{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30019d31-6989-4ead-919f-ba8f2dcc3a9a",
   "metadata": {},
   "source": [
    "# Data Visualisation of COVID-19 in the UK using Sqlite, Pandas and Seaborn Libraries \n",
    "## Part 2a: Extract the Data\n",
    "\n",
    "This is the second notebook in a 3-part series which explores the UK Gov's COVID-19 dashboard data which is publically available for download via a REST API from gov.uk.  We make use of a Sqlite3 database to query this data using SQL and import aggregations into Pandas data frames.  We then use the Seaborn library to visualise the results.\n",
    "\n",
    "In this notebook (Part 2) - we first extract the data using a REST API based on the GOV.UK COVID-19 SDK and then insert the data into empty tables created in Part 1.  Part 3 will then query and visualise the data.\n",
    "\n",
    "The data used in this notebook is publically available and more information can be found here:\n",
    "https://coronavirus.data.gov.uk/details/about-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3578f5-9bfa-41f9-877f-2a2140766ad3",
   "metadata": {},
   "source": [
    "### Configuration and Setup\n",
    "\n",
    "The main library we will use to perform the REST API calls to get the GOV.UK COVID-19 data is the SDK published by GOV.UK.  This will handle the various calls, but also pagination as well and populate the data into a Pandas data-frame.\n",
    "\n",
    "Install the library using `pip install uk-covid19`\n",
    "\n",
    "For more information on the SDK, see: https://pypi.org/project/uk-covid19/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dfe7f4-d20f-4dd2-8bbf-2b57b91c3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uk_covid19 import Cov19API  # Use the UK COVID-19 GOV.UK SDK\n",
    "import pandas as pd              # Pandas library for Dataframes\n",
    "import time                      # Need the Sleep function for API calls\n",
    "import csv                       # For CSV generation\n",
    "from datetime import datetime    # Datetime functionality\n",
    "import re                        # Regular Expression for the snake_case function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba4d6b-6eaa-4693-bcff-cc7060bb0288",
   "metadata": {},
   "source": [
    "### Camel Case to Snake Case Function for Column Names\n",
    "\n",
    "We're going to use a naming standard for the SQL tables based on Snake Case (lowercase and underscore only).  One reason we might do this is because it's more compliant with various database systems such as HiveQL, Amazon Athena, etc.\n",
    "\n",
    "Unfortunately the column naming used by the GOV.UK API is based on Camel Case (mixed case with no spaces).  So the following function will be used to convert the source column names into snake case which will make importing the data easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f868d0a8-3b75-489e-b056-6777806fd896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Convert any string to snake case (lower case and _ for spacing)\n",
    "    Args:        name: input string to convert\n",
    "    Returns:     input string converted to snake case \n",
    "    \"\"\"   \n",
    "    name = re.sub(\"(.)([A-Z][a-z]+)\", r\"\\1_\\2\", name)\n",
    "    name = re.sub(\"[,.]\", \"_\", name)   \n",
    "    name = re.sub(\"[+*&%=()?<>!@#$/\\\\\\\\]\", \"\", name)  \n",
    "\n",
    "    return re.sub(\"([a-z0-9])([A-Z])\", r\"\\1_\\2\", name).lower().replace(\" \",\"_\").replace(\"-\",\"_\").replace(\"__\",\"_\").replace(\"__\",\"_\").replace(\"deaths28\",\"deaths_28\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7614956-8128-4efe-89c5-917056f565c1",
   "metadata": {},
   "source": [
    "### Handling Metrics and Area Types in the REST API\n",
    "\n",
    "If you read the documentation provided at https://coronavirus.data.gov.uk/details/download and https://coronavirus.data.gov.uk/details/developers-guide - you'll see that only a maximum of 5 metrics can be requested via the API in addition to the standard (primary key) metrics: Area Type, Name, Code and Date.\n",
    "\n",
    "This means we have to make multiple API requests for groups of metrics since we can't request all in one go.  Additionally the metrics available differ depending on the Area Type you are requesting.\n",
    "\n",
    "The following provides a configuration in the form of a dictionary object which define the metrics available for each area type.  In addition the metrics are broken down into groups of no more than 5 metrics and this will allow us to iterate in a more generic function.  The default metrics are also provided in a separate list object.\n",
    "\n",
    "This notebook is going to retrieve data for all area types, and for most of the metrics available.  However, this is forever changing so as more metrics become available we simply add them to one or more separate metric groups for the appropriate area type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cfd0f6c-033b-48d4-b3d0-ac50491dd2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_metrics = [\"areaType\",\n",
    "                   \"areaName\",\n",
    "                   \"areaCode\",\n",
    "                   \"date\"]\n",
    "\n",
    "metrics_by_area_type = {\n",
    "    \"overview\" : [\n",
    "        [\"newCasesByPublishDate\",\"cumCasesByPublishDate\",\"cumCasesByPublishDateRate\",\"newCasesBySpecimenDate\",\"cumCasesBySpecimenDate\"],\n",
    "        [\"cumCasesBySpecimenDateRate\",\"newPillarOneTestsByPublishDate\",\"cumPillarOneTestsByPublishDate\"],\n",
    "        [\"newPillarTwoTestsByPublishDate\",\"cumPillarTwoTestsByPublishDate\",\"newPillarThreeTestsByPublishDate\",\"cumPillarThreeTestsByPublishDate\",\"newPillarFourTestsByPublishDate\"],\n",
    "        [\"cumPillarFourTestsByPublishDate\",\"newAdmissions\",\"cumAdmissions\",\"cumTestsByPublishDate\"],\n",
    "        [\"newTestsByPublishDate\",\"covidOccupiedMVBeds\",\"hospitalCases\",\"plannedCapacityByPublishDate\",\"newDeaths28DaysByPublishDate\",\"cumDeaths28DaysByPublishDate\"],\n",
    "        [\"cumDeaths28DaysByPublishDateRate\",\"newDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDateRate\"]\n",
    "    ],\n",
    "    \"nation\" : [\n",
    "        [\"newCasesByPublishDate\",\"cumCasesByPublishDate\",\"cumCasesByPublishDateRate\",\"newCasesBySpecimenDate\",\"cumCasesBySpecimenDate\"],\n",
    "        [\"cumCasesBySpecimenDateRate\",\"maleCases\",\"femaleCases\",\"newPillarOneTestsByPublishDate\",\"cumPillarOneTestsByPublishDate\"],\n",
    "        [\"newPillarTwoTestsByPublishDate\",\"cumPillarTwoTestsByPublishDate\",\"newPillarThreeTestsByPublishDate\",\"cumPillarThreeTestsByPublishDate\"],\n",
    "        [\"newAdmissions\",\"cumAdmissions\",\"cumAdmissionsByAge\",\"cumTestsByPublishDate\"],\n",
    "        [\"newTestsByPublishDate\",\"covidOccupiedMVBeds\",\"hospitalCases\",\"newDeaths28DaysByPublishDate\",\"cumDeaths28DaysByPublishDate\"],\n",
    "        [\"cumDeaths28DaysByPublishDateRate\",\"newDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDateRate\"],\n",
    "        [\"newPeopleVaccinatedFirstDoseByPublishDate\",\"newPeopleVaccinatedSecondDoseByPublishDate\",\"cumPeopleVaccinatedFirstDoseByPublishDate\",\"cumPeopleVaccinatedSecondDoseByPublishDate\"],\n",
    "        [\"newPeopleVaccinatedThirdInjectionByPublishDate\",\"cumPeopleVaccinatedThirdInjectionByPublishDate\"]\n",
    "    ],\n",
    "    \"region\" : [\n",
    "        [\"newCasesByPublishDate\",\"cumCasesByPublishDate\",\"cumCasesByPublishDateRate\",\"newCasesBySpecimenDate\",\"cumCasesBySpecimenDate\"],\n",
    "        [\"cumCasesBySpecimenDateRate\",\"maleCases\",\"femaleCases\",\"newDeaths28DaysByPublishDate\",\"cumDeaths28DaysByPublishDate\"],\n",
    "        [\"cumDeaths28DaysByPublishDateRate\",\"newDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDateRate\"]\n",
    "    ],  \n",
    "    \"nhsRegion\" : [\n",
    "        [\"newAdmissions\",\"cumAdmissions\",\"cumAdmissionsByAge\",\"covidOccupiedMVBeds\",\"hospitalCases\"]\n",
    "    ],  \n",
    "    \"utla\" : [\n",
    "        [\"newCasesByPublishDate\",\"cumCasesByPublishDate\",\"cumCasesByPublishDateRate\",\"newCasesBySpecimenDate\",\"cumCasesBySpecimenDate\"],\n",
    "        [\"cumCasesBySpecimenDateRate\",\"newDeaths28DaysByPublishDate\",\"cumDeaths28DaysByPublishDate\"],\n",
    "        [\"cumDeaths28DaysByPublishDateRate\",\"newDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDateRate\"]\n",
    "    ],\n",
    "    \"ltla\" : [\n",
    "        [\"newCasesByPublishDate\",\"cumCasesByPublishDate\",\"cumCasesByPublishDateRate\",\"newCasesBySpecimenDate\",\"cumCasesBySpecimenDate\"],\n",
    "        [\"cumCasesBySpecimenDateRate\",\"newDeaths28DaysByPublishDate\",\"cumDeaths28DaysByPublishDate\"],\n",
    "        [\"cumDeaths28DaysByPublishDateRate\",\"newDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDate\",\"cumDeaths28DaysByDeathDateRate\"]\n",
    "    ]    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0c466-f8c3-4f5e-b54a-dc9042a3b530",
   "metadata": {},
   "source": [
    "### Extract the Data as CSV by iterating through the metric groups\n",
    "\n",
    "Now we simply iterate through each area type which provides a list of metric groups.  Then we iterate through each metric group (no more than 5 metrics) and combined with the mandatory default metrics we use the SDK to make a REST API call and grab the data into a Pandas dataframe.\n",
    "\n",
    "Unfortunately there is rate limiting implemented for this API as documentated in the fair usage policy: https://coronavirus.data.gov.uk/details/download.  As such we use `time.sleep(1)` to pause for one second between each API call.  So far this has provded sufficient to abide by the fair usage policy.\n",
    "\n",
    "As we iterate through each metric group, we combine all the data together using an outer join merge based on the default metric columns.\n",
    "\n",
    "We then convert the column names to snake case, convert the `date` column to datetime, and finally write the data out to a CSV (so one CSV per area type is generated).\n",
    "\n",
    "**So why CSV and not load straight to the database?** \n",
    "\n",
    "It's common in most ETL/ELT processing systems to initially stage the data before loading into a database - typically to a data-lake of some sort.  Here we simply use the file system and stage the data as CSV.  This means if we have any errors loading the data into the database tables, we have the data in a ready to use format to investigate the issues further.  \n",
    "\n",
    "**NOTE:** The following code will take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5d0343f-2914-4bc5-a258-0a5e7d9bee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:39:54 : Area Type: overview - Metric Group 1 - Num records: 716\n",
      "14:39:55 : Area Type: overview - Metric Group 2 - Num records: 686\n",
      "14:39:57 : Area Type: overview - Metric Group 3 - Num records: 654\n",
      "14:39:58 : Area Type: overview - Metric Group 4 - Num records: 662\n",
      "14:40:00 : Area Type: overview - Metric Group 5 - Num records: 680\n",
      "14:40:01 : Area Type: overview - Metric Group 6 - Num records: 684\n",
      "14:40:03 : Area Type: nation - Metric Group 1 - Num records: 2772\n",
      "14:40:05 : Area Type: nation - Metric Group 2 - Num records: 2760\n",
      "14:40:07 : Area Type: nation - Metric Group 3 - Num records: 2353\n",
      "14:40:09 : Area Type: nation - Metric Group 4 - Num records: 2695\n",
      "14:40:11 : Area Type: nation - Metric Group 5 - Num records: 2706\n",
      "14:40:13 : Area Type: nation - Metric Group 6 - Num records: 2696\n",
      "14:40:15 : Area Type: nation - Metric Group 7 - Num records: 1476\n",
      "14:40:16 : Area Type: nation - Metric Group 8 - Num records: 390\n",
      "14:40:19 : Area Type: region - Metric Group 1 - Num records: 6258\n",
      "14:40:24 : Area Type: region - Metric Group 2 - Num records: 6259\n",
      "14:40:27 : Area Type: region - Metric Group 3 - Num records: 6104\n",
      "14:40:30 : Area Type: nhsRegion - Metric Group 1 - Num records: 4670\n",
      "14:42:44 : Area Type: utla - Metric Group 1 - Num records: 145599\n",
      "14:43:34 : Area Type: utla - Metric Group 2 - Num records: 145565\n",
      "14:44:55 : Area Type: utla - Metric Group 3 - Num records: 127888\n",
      "14:51:43 : Area Type: ltla - Metric Group 1 - Num records: 257827\n",
      "14:53:57 : Area Type: ltla - Metric Group 2 - Num records: 257781\n",
      "14:57:53 : Area Type: ltla - Metric Group 3 - Num records: 237920\n"
     ]
    }
   ],
   "source": [
    "# iterate through each area type (this provides a list of metric groups)\n",
    "# key = areaType, value = list of metric groups (or a list of lists of metrics)\n",
    "for key, value in metrics_by_area_type.items():\n",
    "    \n",
    "    filters = [f\"areaType={key}\"]\n",
    "    \n",
    "    df_merged = pd.DataFrame()\n",
    "    \n",
    "    # iterate through each metric group (at most 5 metrics)\n",
    "    metric_group_index = 1\n",
    "    for metric_group in value:\n",
    "        # we create a dictionary containing the metrics which must also include the default metrics\n",
    "        structure = {}\n",
    "        structure_d = {k: k for k in default_metrics}\n",
    "        structure_m = {k: k for k in metric_group}\n",
    "        structure.update(structure_d)\n",
    "        structure.update(structure_m)\n",
    "\n",
    "        # call the API using the SDK - requires just the Area Type and Metrics requested \n",
    "        api = Cov19API(\n",
    "            filters=filters,\n",
    "            structure=structure\n",
    "        ) \n",
    "        \n",
    "        # grab data as a Pandas dataframe and merge with any previously requested metrics\n",
    "        df = api.get_dataframe() \n",
    "        print(f\"{datetime.now().strftime('%H:%M:%S')} : Area Type: {key} - Metric Group {str(metric_group_index)} - Num records: {len(df)}\")\n",
    "        if df_merged.empty:\n",
    "            df_merged = df\n",
    "        else:\n",
    "            df_merged = df_merged.merge(df, on=default_metrics, how=\"outer\")\n",
    "            \n",
    "        # pause for a second to avoid breaching the fair usage policy\n",
    "        time.sleep(1.0)\n",
    "        metric_group_index += 1\n",
    "     \n",
    "    # all the metrics have now been retrieved and merged so convert columns to snake_case and write out the area type's CSV data\n",
    "    df_merged.rename(columns=camel_to_snake, inplace=True)\n",
    "    df_merged[\"date\"]= pd.to_datetime(df_merged[\"date\"])\n",
    "    df_merged.to_csv(f\"{key}.csv\", index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682a5f6-5461-4918-9802-739f0fc2b940",
   "metadata": {},
   "source": [
    "### Supplementary Downloads\n",
    "\n",
    "We need to download population data for the various geographies (such as UTLA) which are available from GOV.UK.  This will help provide standardised case and death rates between different areas.  \n",
    "\n",
    "As was the case for the COVID-19 data, we snake case the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "066b7b26-f78a-47f9-b81c-5fd55345eb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>area_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGE_ONLY</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>00_04</td>\n",
       "      <td>5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGE_ONLY</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>00_59</td>\n",
       "      <td>69434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE_ONLY</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>05_09</td>\n",
       "      <td>5774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGE_ONLY</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>10_14</td>\n",
       "      <td>5982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGE_ONLY</td>\n",
       "      <td>E06000001</td>\n",
       "      <td>ALL</td>\n",
       "      <td>15_19</td>\n",
       "      <td>5126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  area_code gender    age  population\n",
       "0  AGE_ONLY  E06000001    ALL  00_04        5147\n",
       "1  AGE_ONLY  E06000001    ALL  00_59       69434\n",
       "2  AGE_ONLY  E06000001    ALL  05_09        5774\n",
       "3  AGE_ONLY  E06000001    ALL  10_14        5982\n",
       "4  AGE_ONLY  E06000001    ALL  15_19        5126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_populations = pd.read_csv(f\"https://coronavirus.data.gov.uk/downloads/supplements/ONS-population_2021-08-05.csv\")\n",
    "df_populations.rename(columns=camel_to_snake, inplace=True)\n",
    "df_populations.to_csv(f\"populations.csv\", index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# preview the data\n",
    "df_populations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884d666e-c8db-49f4-9c79-5ff6e19bbad0",
   "metadata": {},
   "source": [
    "### Generating Age/Gender Data from JSON based fields\n",
    "\n",
    "You may have noticed in some of the data files generated (like `nation.csv`) that there are some fields that contain a JSON representation of age bracketed data.  For example, the `male_cases` field contains data that looks like this:\n",
    "\n",
    "`[{'age': '30_to_34', 'rate': 12870.5, 'value': 246652}, {'age': '35_to_39', 'rate': 11484.5, 'value': 212805}]`\n",
    "\n",
    "We'd like to parse this data and convert it into more useable data - i.e. have a data-set which provides case numbers by age (group) and gender in addition to the existing key fields (area and date).\n",
    "\n",
    "Sqlite doesn't have native support for JSON parsing.  Although there are extensions available, this notebook is going to just use the standard Sqlite database and library.  Therefore we're going to transform this data using Pandas Dataframes - first we'll load the `nation.csv` data, perform the transformation and write out the data as a CSV.  Then in the next part of this notebook, we'll load all the CSVs into the Sqlite database.\n",
    "\n",
    "Most of the parsing of JSON is done using the `pd.concat` and `eval` functions as shown below.  Before we do this, we combine the male cases data with the female cases data and derive an additional gender field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d35f890-fda8-41a9-a73d-29b1b9d388d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>area_name</th>\n",
       "      <th>area_code</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>rate</th>\n",
       "      <th>cum_cases</th>\n",
       "      <th>new_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13280</th>\n",
       "      <td>nation</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>male</td>\n",
       "      <td>80_to_84</td>\n",
       "      <td>11476.0</td>\n",
       "      <td>4623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13258</th>\n",
       "      <td>nation</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>male</td>\n",
       "      <td>85_to_89</td>\n",
       "      <td>13363.6</td>\n",
       "      <td>2911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>nation</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>male</td>\n",
       "      <td>85_to_89</td>\n",
       "      <td>13363.6</td>\n",
       "      <td>2911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>nation</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>male</td>\n",
       "      <td>90+</td>\n",
       "      <td>19134.6</td>\n",
       "      <td>1897</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13271</th>\n",
       "      <td>nation</td>\n",
       "      <td>Wales</td>\n",
       "      <td>W92000004</td>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>male</td>\n",
       "      <td>90+</td>\n",
       "      <td>19134.6</td>\n",
       "      <td>1897</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area_type area_name  area_code        date gender       age     rate  \\\n",
       "13280    nation     Wales  W92000004  2022-01-13   male  80_to_84  11476.0   \n",
       "13258    nation     Wales  W92000004  2022-01-13   male  85_to_89  13363.6   \n",
       "13277    nation     Wales  W92000004  2022-01-13   male  85_to_89  13363.6   \n",
       "13255    nation     Wales  W92000004  2022-01-13   male       90+  19134.6   \n",
       "13271    nation     Wales  W92000004  2022-01-13   male       90+  19134.6   \n",
       "\n",
       "       cum_cases  new_cases  \n",
       "13280       4623        0.0  \n",
       "13258       2911        0.0  \n",
       "13277       2911        0.0  \n",
       "13255       1897        0.0  \n",
       "13271       1897        0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the full national level data\n",
    "df = pd.read_csv(\"nation.csv\")\n",
    "\n",
    "# generate male cases sub-set.  Note we want to filter out all the NaNs, empty strings, and empty lists [] since\n",
    "# these cause issues when using the pd.DataFrame constructor - so filter all records where the JSON is 2 characters or less\n",
    "df_cases_m = df.loc[df[\"male_cases\"].str.len()>2, [\"area_type\",\"area_name\",\"area_code\",\"date\",\"male_cases\"]].rename(columns={\"male_cases\": \"cases\"})\n",
    "df_cases_m[\"gender\"] = \"male\"\n",
    "\n",
    "# now repeat the same process for female cases\n",
    "df_cases_f = df.loc[df[\"female_cases\"].str.len()>2,[\"area_type\",\"area_name\",\"area_code\",\"date\",\"female_cases\"]].rename(columns={\"female_cases\": \"cases\"})\n",
    "df_cases_f[\"gender\"] = \"female\"\n",
    "\n",
    "# now combine the two and replace with a new index\n",
    "df_cases_mf = pd.concat([df_cases_m, df_cases_f], ignore_index=True, sort=False)\n",
    "\n",
    "# now we expand the JSON to create additional records/fields and use the index as the key\n",
    "# this will have a column called 'index' which we can use to join on to df_cases_mf to get the area/gender/date fields\n",
    "df_cases_by_age_index = pd.concat([pd.DataFrame(eval(x)) for x in df_cases_mf[\"cases\"]], keys=df_cases_mf.index).reset_index(level=1, drop=True).reset_index()\n",
    "\n",
    "# now we need to use the index to join onto the previous data frame in order to add the key fields (area, date and gender)\n",
    "df_cases_by_age = df_cases_mf[[\"area_type\",\"area_name\",\"area_code\",\"date\",\"gender\"]].merge(df_cases_by_age_index, left_index=True, right_on=\"index\")\n",
    "\n",
    "# drop the index column\n",
    "df_cases_by_age = df_cases_by_age.drop(columns=[\"index\"])\n",
    "\n",
    "# currently the \"value\" column is cumulative cases, but we'd like new cases only so we need to \n",
    "# sort by date, do a group by and then perform a different on the value column\n",
    "df_cases_by_age = df_cases_by_age.sort_values(by=[\"area_type\",\"area_name\",\"area_code\",\"gender\",\"age\",\"date\"])\n",
    "df_cases_by_age[\"new_cases\"] = df_cases_by_age.groupby([\"area_type\",\"area_name\",\"area_code\",\"gender\",\"age\"])[\"value\"].diff().fillna(0)\n",
    "\n",
    "# rename the values column\n",
    "df_cases_by_age = df_cases_by_age.rename(columns={\"value\": \"cum_cases\"})\n",
    "\n",
    "# finally write the cases by ages data out to CSV\n",
    "df_cases_by_age.to_csv(f\"cases.csv\", index=False, quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "# preview the data\n",
    "df_cases_by_age.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d53125-31a1-4d82-ac5d-d4801ace6752",
   "metadata": {},
   "source": [
    "## Part 2b: Load the Data\n",
    "\n",
    "Now we have the data staged a set of CSV files.  All that is left to load these in to the sqlite database that was created by the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37d767c-596b-44a2-977c-4434db5ce686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "sqlite_db_path = \"c19.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109845eb-f3e8-4ccd-adcb-150999639c2d",
   "metadata": {},
   "source": [
    "### Optional: Uncompress Sqlite database file \n",
    "\n",
    "If you compressed the database in the previous notebook, then you'll need to first decompress the file before opening it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239698a8-d55e-4c45-a227-784307effd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with gzip.open(sqlite_db_path + '.gz', 'rb') as f_in:\n",
    "    with open(sqlite_db_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d53be-9686-4500-99dc-8dbe499f4f93",
   "metadata": {},
   "source": [
    "### Open the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e84c792-355d-44ee-b3e0-2fd3af485985",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sqlite_db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98259b-3c0d-47da-b119-cfa622f2030e",
   "metadata": {},
   "source": [
    "### Delete any existing data\n",
    "\n",
    "Although the Pandas function `to_sql` supports 'replace' for the `if_exists` parameter - it does this by dropping and re-creating the table.  Unfortunately doing this loses the original data types.  \n",
    "\n",
    "Normally this wouldn't be important but if the `date` column is not a `DATE` data-type then the Seaborn plots (in the next notebook) do not handle the X-axis labels gracefully.\n",
    "\n",
    "Therefore, we first delete the data in each of the tables, and then perform the insert using 'append' for the `if_exists` parameter (since there should be no data this is safe).  Using the value 'fail' would also not work since the tables already exist - so append is the only way we can insert the data into an existing table and retain the data-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57bb4195-c23c-4398-b534-0d3fdf4ebecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "DELETE FROM c19dashboard_uk__national_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__summary_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__nhsregion_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__region_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__utla_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__ltla_daily_metrics;\n",
    "DELETE FROM c19dashboard_uk__national_cases_by_age_gender;\n",
    "DELETE FROM reference_geography__age_gender_populations;\n",
    "DELETE FROM reference_geography__ltla_utla_region_mappings;\n",
    "\"\"\"\n",
    "_ = conn.executescript(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35c1f0-a7aa-4b63-869c-3d5daaafe36d",
   "metadata": {},
   "source": [
    "### Load the CSV files into the database\n",
    "\n",
    "Now we simply load the data into the database using intermediary Pandas dataframes.  Note this assumes the tables are currently empty - the CSV file is appended to the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a7d0c6-af3b-4db5-b0d6-d9e48134f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f\"nation.csv\").to_sql(\"c19dashboard_uk__national_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"overview.csv\").to_sql(\"c19dashboard_uk__summary_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"nhsRegion.csv\").to_sql(\"c19dashboard_uk__nhsregion_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"region.csv\").to_sql(\"c19dashboard_uk__region_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"utla.csv\").to_sql(\"c19dashboard_uk__utla_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"ltla.csv\").to_sql(\"c19dashboard_uk__ltla_daily_metrics\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"cases.csv\").to_sql(\"c19dashboard_uk__national_cases_by_age_gender\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"populations.csv\").to_sql(\"reference_geography__age_gender_populations\", conn, if_exists=\"append\", index=False)\n",
    "pd.read_csv(f\"ltla_utla_region_mappings.csv\").to_sql(\"reference_geography__ltla_utla_region_mappings\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2dfcf-b06f-485d-bc75-a2ad45308b0e",
   "metadata": {},
   "source": [
    "### Check Row Counts\n",
    "\n",
    "We can run a quick query against the Sqlite database to check the row counts for each of the tables to ensure the data has loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61e75260-9749-4207-a5e6-26dadce8e462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>table</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__national_daily_metrics</th>\n",
       "      <td>2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__summary_daily_metrics</th>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__nhsregion_daily_metrics</th>\n",
       "      <td>4670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__region_daily_metrics</th>\n",
       "      <td>6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__utla_daily_metrics</th>\n",
       "      <td>145626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__ltla_daily_metrics</th>\n",
       "      <td>257879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c19dashboard_uk__national_cases_by_age_gender</th>\n",
       "      <td>26562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_geography__age_gender_populations</th>\n",
       "      <td>10851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reference_geography__ltla_utla_region_mappings</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  rows\n",
       "table                                                 \n",
       "c19dashboard_uk__national_daily_metrics           2776\n",
       "c19dashboard_uk__summary_daily_metrics             716\n",
       "c19dashboard_uk__nhsregion_daily_metrics          4670\n",
       "c19dashboard_uk__region_daily_metrics             6260\n",
       "c19dashboard_uk__utla_daily_metrics             145626\n",
       "c19dashboard_uk__ltla_daily_metrics             257879\n",
       "c19dashboard_uk__national_cases_by_age_gender    26562\n",
       "reference_geography__age_gender_populations      10851\n",
       "reference_geography__ltla_utla_region_mappings     336"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT 'c19dashboard_uk__national_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__national_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__summary_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__summary_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__nhsregion_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__nhsregion_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__region_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__region_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__utla_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__utla_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__ltla_daily_metrics' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__ltla_daily_metrics\n",
    "UNION ALL \n",
    "SELECT 'c19dashboard_uk__national_cases_by_age_gender' AS [table], COUNT(*) AS rows FROM c19dashboard_uk__national_cases_by_age_gender\n",
    "UNION ALL \n",
    "SELECT 'reference_geography__age_gender_populations' AS [table], COUNT(*) AS rows FROM reference_geography__age_gender_populations\n",
    "UNION ALL \n",
    "SELECT 'reference_geography__ltla_utla_region_mappings' AS [table], COUNT(*) AS rows FROM reference_geography__ltla_utla_region_mappings\n",
    "\"\"\"\n",
    "pd.read_sql(sql, conn, index_col=\"table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ffa9a-d97c-4a5f-9175-ba6cd5d34167",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Ensure all changes are committed and then close the Sqlite connection.  Also force garbage collection - at this point, there should be no locks on the database file so it could be zipped up and deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cab9bb07-b1f7-4d52-ba82-73ac50a0c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Commit and close Sqlite connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# Force garbage collection\n",
    "_ = gc.collect(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266cf9c-772d-4794-814a-b6de3abe9aeb",
   "metadata": {},
   "source": [
    "### Optional: Compress Sqlite database file \n",
    "\n",
    "To help keep file sizes small and to allow the database to be easily stored in a Git repo, you may want to compress the database file and then remove the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91cbbf4c-d23e-478d-a6bf-cc0e480010ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "with open(sqlite_db_path, \"rb\") as f_in:\n",
    "    with gzip.open(sqlite_db_path + \".gz\", \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "os.remove(sqlite_db_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
